"""
Tests for supervised multi-agent workflow.

These tests validate the complete supervised workflow where:
1. Orchestrator agent generates TodoList from user query
2. Supervision service executes each step with specialized agents
3. Each step is validated before proceeding to next
4. Dependencies between steps are respected
5. Final aggregated result is returned
"""
import pytest
from core.orchestrator import Orchestrator
from core.llm_wrapper import LLMWrapperConfig


@pytest.fixture
def orchestrator():
    """Create orchestrator with mock backend."""
    llm_config = LLMWrapperConfig(
        base_url="http://localhost:8000",
        api_service="",
        embed_service=""
    )
    orch = Orchestrator(llm_config=llm_config)
    orch.reset_conversation()
    return orch


def test_supervised_simple_task(orchestrator: Orchestrator):
    """Test supervised workflow with simple single-step task."""
    output = orchestrator.process_user_input_supervised("simple task")

    assert output.success, f"Simple task failed: {output.error}"
    assert "Supervised workflow completed" in output.response
    assert len(output.response) > 0


def test_supervised_analyze_codebase(orchestrator: Orchestrator):
    """Test supervised workflow for codebase analysis."""
    output = orchestrator.process_user_input_supervised("analyze codebase")

    assert output.success, f"Analyze codebase failed: {output.error}"
    assert "Supervised workflow completed" in output.response
    assert "Step 1 result" in output.response
    assert "Step 2 result" in output.response
    assert "Step 3 result" in output.response


def test_supervised_todolist_generation(orchestrator: Orchestrator):
    """Test that TodoList is properly generated by orchestrator agent."""
    output = orchestrator.process_user_input_supervised("analyze architecture")

    assert output.success, f"TodoList generation failed: {output.error}"
    assert "Supervised workflow completed" in output.response


def test_supervised_step_validation(orchestrator: Orchestrator):
    """Test that each step is validated before proceeding."""
    output = orchestrator.process_user_input_supervised("simple task")

    assert output.success, f"Step validation failed: {output.error}"
    assert output.agent_id == "supervised_workflow"


def test_supervised_dependency_handling(orchestrator: Orchestrator):
    """Test that step dependencies are respected."""
    output = orchestrator.process_user_input_supervised("analyze architecture")

    assert output.success, f"Dependency handling failed: {output.error}"
    assert "Step 1 result" in output.response
    assert "Step 2 result" in output.response
    assert "Step 3 result" in output.response


def test_supervised_step_failure(orchestrator: Orchestrator):
    """Test that workflow stops when a step fails."""
    output = orchestrator.process_user_input_supervised("task with error")

    assert not output.success, "Workflow should have failed"
    assert "step_2_failed" in output.error or "agent_error" in output.error
    assert "step_2" in output.response.lower() or "failed" in output.response.lower()


def test_supervised_dependency_not_met(orchestrator: Orchestrator):
    """Test behavior when a step dependency fails."""
    output = orchestrator.process_user_input_supervised("task with error")

    assert not output.success, "Workflow should have failed due to step 2 error"
    assert output.error is not None


def test_supervised_error_propagation(orchestrator: Orchestrator):
    """Test that errors are properly propagated to user."""
    output = orchestrator.process_user_input_supervised("task with error")

    assert not output.success
    assert len(output.response) > 0, "Error message should not be empty"
    assert "Step" in output.response or "failed" in output.response.lower()
